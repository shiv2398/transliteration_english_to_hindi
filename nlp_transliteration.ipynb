{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:32:59.575240Z",
     "iopub.status.busy": "2022-11-24T22:32:59.574993Z",
     "iopub.status.idle": "2022-11-24T22:33:10.343347Z",
     "shell.execute_reply": "2022-11-24T22:33:10.342471Z",
     "shell.execute_reply.started": "2022-11-24T22:32:59.575210Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 05:30:04.436603: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-25 05:30:05.000918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-25 05:30:05.001007: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-25 05:30:07.128479: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-25 05:30:07.128657: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-25 05:30:07.128671: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:16.668992Z",
     "iopub.status.busy": "2022-11-24T22:33:16.668583Z",
     "iopub.status.idle": "2022-11-24T22:33:19.945551Z",
     "shell.execute_reply": "2022-11-24T22:33:19.944009Z",
     "shell.execute_reply.started": "2022-11-24T22:33:16.668954Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('english_hindi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:19.948748Z",
     "iopub.status.busy": "2022-11-24T22:33:19.948460Z",
     "iopub.status.idle": "2022-11-24T22:33:19.954260Z",
     "shell.execute_reply": "2022-11-24T22:33:19.952964Z",
     "shell.execute_reply.started": "2022-11-24T22:33:19.948722Z"
    }
   },
   "outputs": [],
   "source": [
    "t_data=train_data[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:19.956077Z",
     "iopub.status.busy": "2022-11-24T22:33:19.955638Z",
     "iopub.status.idle": "2022-11-24T22:33:19.990194Z",
     "shell.execute_reply": "2022-11-24T22:33:19.989174Z",
     "shell.execute_reply.started": "2022-11-24T22:33:19.956051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JANAMDIVAS</th>\n",
       "      <th>^जन्मदिवस$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAKHA</td>\n",
       "      <td>^रक्खा$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MILIJULI</td>\n",
       "      <td>^मिलीजुली$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JAANCHON</td>\n",
       "      <td>^जांचों$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAMKATA</td>\n",
       "      <td>^चमकता$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KAYIYON</td>\n",
       "      <td>^कईयों$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  JANAMDIVAS  ^जन्मदिवस$\n",
       "0      RAKHA     ^रक्खा$\n",
       "1   MILIJULI  ^मिलीजुली$\n",
       "2   JAANCHON    ^जांचों$\n",
       "3   CHAMKATA     ^चमकता$\n",
       "4    KAYIYON     ^कईयों$"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:19.993437Z",
     "iopub.status.busy": "2022-11-24T22:33:19.992253Z",
     "iopub.status.idle": "2022-11-24T22:33:20.008137Z",
     "shell.execute_reply": "2022-11-24T22:33:20.006281Z",
     "shell.execute_reply.started": "2022-11-24T22:33:19.993376Z"
    }
   },
   "outputs": [],
   "source": [
    "target_words =  t_data['^जन्मदिवस$'].tolist()\n",
    "input_words =  t_data['JANAMDIVAS'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:20.010615Z",
     "iopub.status.busy": "2022-11-24T22:33:20.010330Z",
     "iopub.status.idle": "2022-11-24T22:33:20.024915Z",
     "shell.execute_reply": "2022-11-24T22:33:20.023049Z",
     "shell.execute_reply.started": "2022-11-24T22:33:20.010587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAKHA\n",
      "^रक्खा$\n",
      "Total number of input words 100000\n",
      "Total number of target words 100000\n"
     ]
    }
   ],
   "source": [
    "print(input_words[0])\n",
    "print(target_words[0])\n",
    "print(f\"Total number of input words {len(input_words)}\")\n",
    "print(f\"Total number of target words {len(target_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:20.026920Z",
     "iopub.status.busy": "2022-11-24T22:33:20.026580Z",
     "iopub.status.idle": "2022-11-24T22:33:20.054145Z",
     "shell.execute_reply": "2022-11-24T22:33:20.052562Z",
     "shell.execute_reply.started": "2022-11-24T22:33:20.026885Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_vocab(input_words, target_words):\n",
    "  input_vocab = set()\n",
    "  target_vocab = set()\n",
    "  for input_word, target_word in zip(input_words, target_words):\n",
    "      input_vocab.update(set(input_word))\n",
    "      target_vocab.update(set(target_word))\n",
    "  return input_vocab, target_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:20.055735Z",
     "iopub.status.busy": "2022-11-24T22:33:20.055520Z",
     "iopub.status.idle": "2022-11-24T22:33:20.291360Z",
     "shell.execute_reply": "2022-11-24T22:33:20.289812Z",
     "shell.execute_reply.started": "2022-11-24T22:33:20.055710Z"
    }
   },
   "outputs": [],
   "source": [
    "input_vocab, target_vocab = build_vocab(input_words, target_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:20.292963Z",
     "iopub.status.busy": "2022-11-24T22:33:20.292715Z",
     "iopub.status.idle": "2022-11-24T22:33:20.306463Z",
     "shell.execute_reply": "2022-11-24T22:33:20.305225Z",
     "shell.execute_reply.started": "2022-11-24T22:33:20.292938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hindi characters 26\n",
      "Total english characters 70\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total hindi characters {len(input_vocab)}\")\n",
    "print(f\"Total english characters {len(target_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:20.308069Z",
     "iopub.status.busy": "2022-11-24T22:33:20.307785Z",
     "iopub.status.idle": "2022-11-24T22:33:20.321528Z",
     "shell.execute_reply": "2022-11-24T22:33:20.320011Z",
     "shell.execute_reply.started": "2022-11-24T22:33:20.308035Z"
    }
   },
   "outputs": [],
   "source": [
    "input_vocab = sorted(list(input_vocab))\n",
    "target_vocab = sorted(list(target_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:20.322916Z",
     "iopub.status.busy": "2022-11-24T22:33:20.322669Z",
     "iopub.status.idle": "2022-11-24T22:33:20.340712Z",
     "shell.execute_reply": "2022-11-24T22:33:20.338290Z",
     "shell.execute_reply.started": "2022-11-24T22:33:20.322888Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_vocab)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:20.343585Z",
     "iopub.status.busy": "2022-11-24T22:33:20.343362Z",
     "iopub.status.idle": "2022-11-24T22:33:20.379358Z",
     "shell.execute_reply": "2022-11-24T22:33:20.378105Z",
     "shell.execute_reply.started": "2022-11-24T22:33:20.343559Z"
    }
   },
   "outputs": [],
   "source": [
    "num_encoder_tokens = len(input_vocab)\n",
    "num_decoder_tokens = len(target_vocab)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_words])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:20.380622Z",
     "iopub.status.busy": "2022-11-24T22:33:20.380349Z",
     "iopub.status.idle": "2022-11-24T22:33:20.413102Z",
     "shell.execute_reply": "2022-11-24T22:33:20.411395Z",
     "shell.execute_reply.started": "2022-11-24T22:33:20.380597Z"
    }
   },
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max([len(txt) for txt in input_words])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:20.415122Z",
     "iopub.status.busy": "2022-11-24T22:33:20.414392Z",
     "iopub.status.idle": "2022-11-24T22:33:20.452785Z",
     "shell.execute_reply": "2022-11-24T22:33:20.449903Z",
     "shell.execute_reply.started": "2022-11-24T22:33:20.415081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100000\n",
      "Number of unique input tokens: 26\n",
      "Number of unique output tokens: 70\n",
      "Max sequence length for inputs: 25\n",
      "Max sequence length for outputs: 30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_encoder_tokens = len(input_vocab)\n",
    "num_decoder_tokens = len(target_vocab)\n",
    "print('Number of samples:', len(input_words))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:20.455682Z",
     "iopub.status.busy": "2022-11-24T22:33:20.455267Z",
     "iopub.status.idle": "2022-11-24T22:33:20.463448Z",
     "shell.execute_reply": "2022-11-24T22:33:20.460228Z",
     "shell.execute_reply.started": "2022-11-24T22:33:20.455653Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "encoder_input_data = np.zeros((len(input_words), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "decoder_input_data = np.zeros((len(input_words), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "decoder_target_data = np.zeros( (len(input_words), max_decoder_seq_length, num_decoder_tokens), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:22.611353Z",
     "iopub.status.busy": "2022-11-24T22:33:22.610836Z",
     "iopub.status.idle": "2022-11-24T22:33:22.620703Z",
     "shell.execute_reply": "2022-11-24T22:33:22.617421Z",
     "shell.execute_reply.started": "2022-11-24T22:33:22.611323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input shape (100000, 25, 26)\n",
      "decoder input shape (100000, 30, 70)\n",
      "decoder target shape (100000, 30, 70)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"encoder input shape {encoder_input_data.shape}\")\n",
    "print(f\"decoder input shape {decoder_input_data.shape}\")\n",
    "print(f\"decoder target shape {decoder_target_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:23.230502Z",
     "iopub.status.busy": "2022-11-24T22:33:23.230019Z",
     "iopub.status.idle": "2022-11-24T22:33:24.975768Z",
     "shell.execute_reply": "2022-11-24T22:33:24.973813Z",
     "shell.execute_reply.started": "2022-11-24T22:33:23.230474Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_words, target_words)):\n",
    "  for t, char in enumerate(input_text):\n",
    "    encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "  # for the rest of sentence, mark it as space\n",
    "  #encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "\n",
    "  for t, char in enumerate(target_text):\n",
    "    # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "    decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "    if t > 0:\n",
    "      # decoder_target_data will be ahead by one timestep\n",
    "      # and will not include the start character.\n",
    "      decoder_target_data[i, t-1, target_token_index[char]] = 1.0\n",
    "      # for the rest of sentence, mark it as space\n",
    "      #decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:24.978659Z",
     "iopub.status.busy": "2022-11-24T22:33:24.978343Z",
     "iopub.status.idle": "2022-11-24T22:33:24.986337Z",
     "shell.execute_reply": "2022-11-24T22:33:24.985321Z",
     "shell.execute_reply.started": "2022-11-24T22:33:24.978633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 25, 26), (100000, 30, 70), 26)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape,decoder_input_data.shape,num_encoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T22:33:24.988522Z",
     "iopub.status.busy": "2022-11-24T22:33:24.988069Z",
     "iopub.status.idle": "2022-11-24T22:33:25.003357Z",
     "shell.execute_reply": "2022-11-24T22:33:25.001755Z",
     "shell.execute_reply.started": "2022-11-24T22:33:24.988484Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "EMBEDDING_SIZE = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T23:08:27.026690Z",
     "iopub.status.busy": "2022-11-24T23:08:27.026391Z",
     "iopub.status.idle": "2022-11-24T23:08:28.336476Z",
     "shell.execute_reply": "2022-11-24T23:08:28.335107Z",
     "shell.execute_reply.started": "2022-11-24T23:08:27.026653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Restore the model and construct the encoder and decoder.\n",
    "model = load_model('model.h5')\n",
    "# model = load_model(\"model_v1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T23:08:28.338899Z",
     "iopub.status.busy": "2022-11-24T23:08:28.338557Z",
     "iopub.status.idle": "2022-11-24T23:08:29.136654Z",
     "shell.execute_reply": "2022-11-24T23:08:29.135159Z",
     "shell.execute_reply.started": "2022-11-24T23:08:28.338840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 70, 256)\n",
      "Encoder_inputs: (None, None, 26)\n",
      "(None, None, 17920)\n"
     ]
    }
   ],
   "source": [
    "decoder_embedding = tf.keras.layers.Embedding(num_decoder_tokens, latent_dim)\n",
    "decoder_inputs_em = decoder_embedding(decoder_inputs)\n",
    "print(decoder_inputs_em.shape)\n",
    "# Predictions\n",
    "encoder_inputs = model.input[0]\n",
    "print('Encoder_inputs:',encoder_inputs.shape)# input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[6].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_inputs_em = decoder_embedding(decoder_inputs)\n",
    "\n",
    "# since embedding layer will add one more dim, we need to flatten last 2 dims\n",
    "decoder_reshape = Reshape((-1, decoder_inputs_em.shape[2] * decoder_inputs_em.shape[3]))\n",
    "decoder_inputs_re = decoder_reshape(decoder_inputs_em)\n",
    "print(decoder_inputs_re.shape)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_lstm = model.layers[7] # lstm_2\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs_re, initial_state=decoder_states_inputs\n",
    ")\n",
    "\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "\n",
    "decoder_dense = model.layers[-1]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T23:08:29.138775Z",
     "iopub.status.busy": "2022-11-24T23:08:29.138539Z",
     "iopub.status.idle": "2022-11-24T23:08:29.145552Z",
     "shell.execute_reply": "2022-11-24T23:08:29.144032Z",
     "shell.execute_reply.started": "2022-11-24T23:08:29.138748Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T23:08:29.768189Z",
     "iopub.status.busy": "2022-11-24T23:08:29.767931Z",
     "iopub.status.idle": "2022-11-24T23:08:29.779934Z",
     "shell.execute_reply": "2022-11-24T23:08:29.778755Z",
     "shell.execute_reply.started": "2022-11-24T23:08:29.768164Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_target(input_string):\n",
    "  # convert for encoding \n",
    "  input_data = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "  for t, char in enumerate(input_string):\n",
    "    input_data[0, t, input_token_index[char]] = 1.\n",
    "\n",
    "  # Encode the input as state vectors.\n",
    "  states_value = encoder_model(input_data)\n",
    "\n",
    "   # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1, num_decoder_tokens), dtype='float32')\n",
    "  # Populate the first character of target sequence with the start character.\n",
    "  target_seq[0, 0, target_token_index['^']] = 1.0\n",
    "\n",
    "  stop_condition = False\n",
    "  decoded_sentence = \"\"\n",
    "\n",
    "  while True:\n",
    "    output_tokens, d_h, d_c = decoder_model.predict([target_seq] + states_value)\n",
    "    # Sample a token\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "\n",
    "    # Exit condition: either hit max length\n",
    "    # or find stop character.\n",
    "    if sampled_char == \"$\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "      break\n",
    "      \n",
    "    decoded_sentence += sampled_char\n",
    "\n",
    "    # Update the target sequence (of length 1).\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "    # Update states\n",
    "    states_value = [d_h, d_c]\n",
    "  return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T23:29:37.583479Z",
     "iopub.status.busy": "2022-11-24T23:29:37.582896Z",
     "iopub.status.idle": "2022-11-24T23:29:37.657664Z",
     "shell.execute_reply": "2022-11-24T23:29:37.656303Z",
     "shell.execute_reply.started": "2022-11-24T23:29:37.583390Z"
    }
   },
   "outputs": [],
   "source": [
    "test_input = 'SAHITYA'\n",
    "predicted_string = predict_target(test_input)\n",
    "predicted_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
